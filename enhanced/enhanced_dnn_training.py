import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import joblib
import os

# ====== åƒæ•¸è¨­å®š ======
DATASET_FILE = "./enhanced_dataset_all_topologies.csv"
LABEL_MAP_FILE = "./enhanced_label_mappings.pkl"
MODEL_NAME = "topology_aware_dnn_model.keras"
SCALER_NAME = "./enhanced_scaler.pkl"
RESULTS_DIR = "./training_results"

os.makedirs(RESULTS_DIR, exist_ok=True)

# ====== è¼‰å…¥ç°¡åŒ–å¾Œçš„æ•¸æ“šé›† ======
print("ğŸ“¥ è¼‰å…¥ç°¡åŒ–æ•¸æ“šé›†...")
df = pd.read_csv(DATASET_FILE)
with open(LABEL_MAP_FILE, 'rb') as f:
    label_info = pickle.load(f)

X = df.iloc[:, :-1].values  # å‰65ç¶­ï¼š64ç¶­TM + 1ç¶­æ‹“æ’²
y = df['label'].values      # ç°¡åŒ–å¾Œçš„æ¨™ç±¤ï¼šæœ€å¤§æ³¢é•·ç´¢å¼•

print(f"åŸå§‹æ•¸æ“šå½¢ç‹€: X={X.shape}, y={y.shape}")
print(f"é¡åˆ¥æ•¸é‡: {len(np.unique(y))} (ç°¡åŒ–å¾Œ)")
print(f"ç‰¹å¾µç¶­åº¦: {X.shape[1]} (64ç¶­TM + 1ç¶­æ‹“æ’²)")

# ====== æ•¸æ“šåˆ†ä½ˆåˆ†æ ======
print(f"\nğŸ“Š ç°¡åŒ–æ¨™ç±¤åˆ†ä½ˆ:")
label_counts = Counter(y)
for label, count in sorted(label_counts.items()):
    percentage = count / len(y) * 100
    print(f"  æœ€å¤§æ³¢é•· {label}: {count} æ¨£æœ¬ ({percentage:.1f}%)")

# ====== æ‹“æ’²åˆ†ä½ˆåˆ†æ ======
topo_encoding = {'full_mesh': 0, 'ring': 1, 'mesh': 2, 'random': 3}
reverse_topo = {v: k for k, v in topo_encoding.items()}

print(f"\nğŸ“Š å„æ‹“æ’²æ¨£æœ¬åˆ†ä½ˆ:")
for topo_code, topo_name in reverse_topo.items():
    topo_samples = np.sum(X[:, -1] == topo_code)
    percentage = topo_samples / len(X) * 100
    print(f"  {topo_name.upper()}: {topo_samples} æ¨£æœ¬ ({percentage:.1f}%)")

# ====== ä¿®æ­£ç‰¹å¾µæ¨™æº–åŒ–ï¼šåªæ¨™æº–åŒ–TMç‰¹å¾µ ======
print("\nğŸ”§ é€²è¡Œç‰¹å¾µæ¨™æº–åŒ–...")
X_tm = X[:, :-1]    # å‰64ç¶­ï¼šæµé‡çŸ©é™£ç‰¹å¾µ
X_topo = X[:, -1:]  # æœ€å¾Œ1ç¶­ï¼šæ‹“æ’²ç·¨ç¢¼

# åªå°TMç‰¹å¾µé€²è¡Œæ¨™æº–åŒ–
scaler = StandardScaler()
X_tm_scaled = scaler.fit_transform(X_tm)

# é‡æ–°çµ„åˆï¼šæ¨™æº–åŒ–çš„TM + åŸå§‹çš„æ‹“æ’²ç·¨ç¢¼
X_scaled = np.concatenate([X_tm_scaled, X_topo], axis=1)
joblib.dump(scaler, SCALER_NAME)

print(f"âœ… ç‰¹å¾µæ¨™æº–åŒ–å®Œæˆï¼Œæ¨™æº–åŒ–å™¨å·²å„²å­˜è‡³ {SCALER_NAME}")

# ====== æ¨™ç±¤é‡æ–°æ˜ å°„ç‚ºé€£çºŒæ•´æ•¸ ======
unique_labels = np.unique(y)
num_classes = len(unique_labels)

# å»ºç«‹æ¨™ç±¤æ˜ å°„ï¼šåŸå§‹æ¨™ç±¤ -> é€£çºŒæ•´æ•¸
label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(unique_labels))}
reverse_label_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}

print(f"ğŸ“Š æ¨™ç±¤é‡æ–°æ˜ å°„:")
for old_label, new_label in label_mapping.items():
    count = np.sum(y == old_label)
    print(f"  æœ€å¤§æ³¢é•· {old_label} -> é¡åˆ¥ {new_label} ({count} æ¨£æœ¬)")

# å°‡åŸå§‹æ¨™ç±¤æ˜ å°„ç‚ºé€£çºŒæ•´æ•¸
y_mapped = np.array([label_mapping[label] for label in y])
y_categorical = to_categorical(y_mapped, num_classes=num_classes)

print(f"ğŸ“Š å°‡æ¨™ç±¤è½‰æ›ç‚º {num_classes} é¡åˆ†é¡å•é¡Œ")

# ====== ç¢ºä¿æ‹“æ’²å¹³è¡¡çš„æ•¸æ“šåˆ‡åˆ† ======
print("\nğŸ”€ é€²è¡Œæ‹“æ’²å¹³è¡¡çš„æ•¸æ“šåˆ‡åˆ†...")

# ä½¿ç”¨æ‹“æ’²ç·¨ç¢¼ä½œç‚ºåˆ†å±¤ä¾æ“šï¼Œç¢ºä¿æ¯ç¨®æ‹“æ’²åœ¨è¨“ç·´/æ¸¬è©¦é›†ä¸­æ¯”ä¾‹ä¸€è‡´
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_categorical,
    test_size=0.2,
    random_state=42,
    stratify=X_scaled[:, -1]  # æŒ‰æ‹“æ’²IDåˆ†å±¤
)

print(f"è¨“ç·´é›†å¤§å°: {X_train.shape[0]}")
print(f"æ¸¬è©¦é›†å¤§å°: {X_test.shape[0]}")

# æª¢æŸ¥è¨“ç·´å’Œæ¸¬è©¦é›†çš„æ‹“æ’²åˆ†ä½ˆ
print(f"\nğŸ“Š è¨“ç·´é›†æ‹“æ’²åˆ†ä½ˆ:")
for topo_code, topo_name in reverse_topo.items():
    train_topo_count = np.sum(X_train[:, -1] == topo_code)
    percentage = train_topo_count / len(X_train) * 100
    print(f"  {topo_name.upper()}: {train_topo_count} æ¨£æœ¬ ({percentage:.1f}%)")

print(f"\nğŸ“Š æ¸¬è©¦é›†æ‹“æ’²åˆ†ä½ˆ:")
for topo_code, topo_name in reverse_topo.items():
    test_topo_count = np.sum(X_test[:, -1] == topo_code)
    percentage = test_topo_count / len(X_test) * 100
    print(f"  {topo_name.upper()}: {test_topo_count} æ¨£æœ¬ ({percentage:.1f}%)")

# ====== å»ºç«‹ç©©å¥çš„MLPæ¨¡å‹ ======
def create_robust_mlp_model(input_dim, num_classes):
    """å»ºç«‹ç©©å¥çš„å¤šå±¤æ„ŸçŸ¥æ©Ÿæ¨¡å‹"""
    model = Sequential([
        # è¼¸å…¥å±¤
        Dense(512, activation='relu', input_shape=(input_dim,)),
        BatchNormalization(),
        Dropout(0.4),
        
        # éš±è—å±¤ 1
        Dense(256, activation='relu'),
        BatchNormalization(),
        Dropout(0.4),
        
        # éš±è—å±¤ 2
        Dense(128, activation='relu'),
        BatchNormalization(),
        Dropout(0.4),
        
        # è¼¸å‡ºå±¤
        Dense(num_classes, activation='softmax')
    ])
    
    return model

print("\nğŸ—ï¸ å»ºç«‹ç©©å¥çš„MLPæ¨¡å‹...")
model = create_robust_mlp_model(X_scaled.shape[1], num_classes)

# ç·¨è­¯æ¨¡å‹
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# ====== è¨“ç·´è¨­å®šï¼ˆåŠ å…¥æ—©åœæ©Ÿåˆ¶ï¼‰======
callbacks = [
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=15,
        min_lr=1e-6,
        verbose=1
    ),
    ModelCheckpoint(
        f'{RESULTS_DIR}/{MODEL_NAME}',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    ),
    EarlyStopping(
        monitor='val_loss',
        patience=25,
        restore_best_weights=True,
        verbose=1
    )
]

# ====== è¨“ç·´æ¨¡å‹ ======
print("\nğŸš€ é–‹å§‹è¨“ç·´ç©©å¥MLPæ¨¡å‹...")
history = model.fit(
    X_train, y_train,
    epochs=300,              # å¢åŠ è¨“ç·´è¼ªæ•¸
    batch_size=32,
    validation_split=0.15,
    callbacks=callbacks,
    verbose=1
)

# ====== æ•´é«”æ¨¡å‹è©•ä¼° ======
print("\nğŸ“Š è©•ä¼°æ•´é«”æ¨¡å‹æ€§èƒ½...")
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"æ•´é«”æ¸¬è©¦æº–ç¢ºç‡: {test_acc:.4f}")

# ====== é—œéµæ–°å¢ï¼šæŒ‰æ‹“æ’²åˆ†é …è©•ä¼° ======
print("\nğŸ“Š å„æ‹“æ’²æº–ç¢ºç‡åˆ†æ:")
y_pred = model.predict(X_test, verbose=0)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

# å°‡é æ¸¬çš„é¡åˆ¥ç´¢å¼•æ˜ å°„å›åŸå§‹æ³¢é•·ç´¢å¼•ï¼Œç”¨æ–¼æ›´å¥½çš„è§£é‡‹
y_pred_wavelengths = np.array([reverse_label_mapping[cls] for cls in y_pred_classes])
y_test_wavelengths = np.array([reverse_label_mapping[cls] for cls in y_test_classes])

topo_results = {}
for topo_code, topo_name in reverse_topo.items():
    # ç¯©é¸å±¬æ–¼ç•¶å‰æ‹“æ’²çš„æ¸¬è©¦æ¨£æœ¬
    topo_test_mask = X_test[:, -1] == topo_code
    topo_sample_count = np.sum(topo_test_mask)
    
    if topo_sample_count > 0:
        # è¨ˆç®—è©²æ‹“æ’²çš„æº–ç¢ºç‡
        topo_accuracy = np.mean(
            y_pred_classes[topo_test_mask] == y_test_classes[topo_test_mask]
        )
        
        # çµ±è¨ˆè©²æ‹“æ’²çš„é æ¸¬æ³¢é•·åˆ†ä½ˆ
        topo_pred_wavelengths = y_pred_wavelengths[topo_test_mask]
        topo_true_wavelengths = y_test_wavelengths[topo_test_mask]
        
        topo_results[topo_name] = {
            'accuracy': topo_accuracy,
            'samples': topo_sample_count,
            'pred_wavelengths': topo_pred_wavelengths,
            'true_wavelengths': topo_true_wavelengths
        }
        
        status = "âœ…" if topo_accuracy >= 0.8 else "âš ï¸" if topo_accuracy >= 0.6 else "âŒ"
        avg_pred_wavelength = np.mean(topo_pred_wavelengths)
        avg_true_wavelength = np.mean(topo_true_wavelengths)
        
        print(f"  {status} {topo_name.upper()}: {topo_accuracy:.4f} (æ¨£æœ¬æ•¸: {topo_sample_count})")
        print(f"      å¹³å‡é æ¸¬æ³¢é•·: {avg_pred_wavelength:.1f}, å¹³å‡çœŸå¯¦æ³¢é•·: {avg_true_wavelength:.1f}")
    else:
        print(f"  âš ï¸ {topo_name.upper()}: ç„¡æ¸¬è©¦æ¨£æœ¬")

# ====== çµæœè¦–è¦ºåŒ– ======
def plot_comprehensive_results():
    """ç¹ªè£½å®Œæ•´çš„è¨“ç·´èˆ‡è©•ä¼°çµæœ"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. è¨“ç·´æº–ç¢ºç‡æ›²ç·š
    ax1.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
    ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80% Target')
    ax1.set_title('Training & Validation Accuracy', fontsize=14)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. è¨“ç·´æå¤±æ›²ç·š
    ax2.plot(history.history['loss'], label='Train Loss', linewidth=2)
    ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
    ax2.set_title('Training & Validation Loss', fontsize=14)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. å„æ‹“æ’²æº–ç¢ºç‡å°æ¯”
    if topo_results:
        topos = list(topo_results.keys())
        accuracies = [topo_results[t]['accuracy'] for t in topos]
        colors = ['green' if acc >= 0.8 else 'orange' if acc >= 0.6 else 'red' for acc in accuracies]
        
        bars = ax3.bar([t.upper() for t in topos], accuracies, color=colors, alpha=0.8)
        ax3.set_title('Accuracy by Topology', fontsize=14)
        ax3.set_ylabel('Accuracy')
        ax3.set_ylim(0, 1)
        ax3.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80% Target')
        
        # åœ¨æŸ±ç‹€åœ–ä¸Šæ¨™è¨»æ•¸å€¼
        for bar, acc in zip(bars, accuracies):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                    f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
        
        ax3.legend()
        ax3.grid(True, alpha=0.3)
    
    # 4. é æ¸¬ä¿¡å¿ƒåº¦åˆ†ä½ˆ
    confidence_scores = np.max(y_pred, axis=1)
    ax4.hist(confidence_scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    ax4.axvline(x=0.8, color='red', linestyle='--', alpha=0.7, label='80% Confidence')
    ax4.set_title('Prediction Confidence Distribution', fontsize=14)
    ax4.set_xlabel('Confidence Score')
    ax4.set_ylabel('Frequency')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{RESULTS_DIR}/comprehensive_training_results.png', dpi=300, bbox_inches='tight')
    plt.show()

plot_comprehensive_results()

# ====== å„²å­˜è¨“ç·´çµæœ ======
results_summary = {
    'overall_test_accuracy': test_acc,
    'topology_results': topo_results,
    'model_type': 'robust_mlp',
    'model_params': {
        'input_dim': X_scaled.shape[1],
        'num_classes': num_classes,
        'architecture': 'MLP: 512->256->128->classes'
    },
    'training_samples': len(X_train),
    'test_samples': len(X_test),
    'label_type': 'max_wavelength_index',
    'label_mapping': label_mapping,
    'reverse_label_mapping': reverse_label_mapping,
    'original_unique_labels': unique_labels.tolist()
}

with open(f'{RESULTS_DIR}/results_summary.pkl', 'wb') as f:
    pickle.dump(results_summary, f)

# ====== æœ€çµ‚è¨ºæ–·å ±å‘Š ======
print("\n" + "="*70)
print("ğŸ¯ æ‹“æ’²æ„ŸçŸ¥DNNè¨“ç·´å®Œæˆå ±å‘Š")
print("="*70)

print(f"ğŸ”§ æ¨¡å‹æ¶æ§‹: ç©©å¥MLP (512â†’256â†’128â†’{num_classes})")
print(f"ğŸ“Š æ•´é«”æ¸¬è©¦æº–ç¢ºç‡: {test_acc:.4f}")
print(f"ğŸ“ˆ æ¨™ç±¤é¡åˆ¥æ•¸: {num_classes} (å¾æ•¸åƒé¡ç°¡åŒ–)")
print(f"ğŸ·ï¸ æ¨™ç±¤æ˜ å°„: {dict(sorted(reverse_label_mapping.items()))}")

print(f"\nğŸ“Š å„æ‹“æ’²è©³ç´°æ€§èƒ½:")
all_above_80 = True
total_weighted_acc = 0
total_samples = 0

for topo, result in topo_results.items():
    accuracy = result['accuracy']
    samples = result['samples']
    status = "âœ…" if accuracy >= 0.8 else "âš ï¸" if accuracy >= 0.6 else "âŒ"
    
    print(f"  {status} {topo.upper()}:")
    print(f"      æº–ç¢ºç‡: {accuracy:.4f}")
    print(f"      æ¨£æœ¬æ•¸: {samples}")
    print(f"      ç‹€æ…‹: {'é”æ¨™' if accuracy >= 0.8 else 'éœ€æ”¹é€²'}")
    
    total_weighted_acc += accuracy * samples
    total_samples += samples
    
    if accuracy < 0.8:
        all_above_80 = False

weighted_avg_acc = total_weighted_acc / total_samples if total_samples > 0 else 0

print(f"\nğŸ“ˆ ç¶œåˆçµ±è¨ˆ:")
print(f"  åŠ æ¬Šå¹³å‡æº–ç¢ºç‡: {weighted_avg_acc:.4f}")
print(f"  é”æ¨™æ‹“æ’²æ•¸é‡: {sum(1 for result in topo_results.values() if result['accuracy'] >= 0.8)}/{len(topo_results)}")

if all_above_80:
    print(f"\nğŸ‰ æ­å–œï¼æ‰€æœ‰æ‹“æ’²éƒ½é”åˆ°80%ä»¥ä¸Šæº–ç¢ºç‡ç›®æ¨™ï¼")
    print(f"   æ¨™ç±¤ç°¡åŒ–ç­–ç•¥æˆåŠŸï¼šå¾æ•¸åƒé¡é™è‡³{num_classes}é¡")
    print(f"   æ³¢é•·é æ¸¬ç¯„åœï¼š{min(unique_labels)} ~ {max(unique_labels)}")
else:
    print(f"\nâš ï¸ éƒ¨åˆ†æ‹“æ’²æœªå®Œå…¨é”æ¨™ï¼Œä½†ç›¸æ¯”åŸä¾†çš„0%å·²æœ‰å·¨å¤§æ”¹å–„")
    under_performing = [topo for topo, result in topo_results.items() if result['accuracy'] < 0.8]
    print(f"   éœ€è¦é‡é»é—œæ³¨: {', '.join(under_performing)}")

print(f"\nğŸ“ æ‰€æœ‰çµæœå·²å„²å­˜è‡³ {RESULTS_DIR}/")
print(f"ğŸ“ æ¨¡å‹å·²å„²å­˜è‡³ {RESULTS_DIR}/{MODEL_NAME}")
print(f"ğŸ“ ç‰¹å¾µæ¨™æº–åŒ–å™¨å·²å„²å­˜è‡³ {SCALER_NAME}")

# ====== å„ªåŒ–å»ºè­° ======
print(f"\nğŸ’¡ å¾ŒçºŒå„ªåŒ–å»ºè­°:")
print(f"  1. å¦‚æœ‰æ‹“æ’²æœªé”æ¨™ï¼Œå¯è€ƒæ…®å¢åŠ è©²æ‹“æ’²çš„è¨“ç·´æ¨£æœ¬")
print(f"  2. å¯å˜—è©¦èª¿æ•´å­¸ç¿’ç‡æˆ–ç¶²çµ¡æ¶æ§‹")
print(f"  3. ç›£æ§éæ“¬åˆï¼šé©—è­‰æº–ç¢ºç‡ vs è¨“ç·´æº–ç¢ºç‡")

high_confidence_count = np.sum(np.max(y_pred, axis=1) > 0.8)
print(f"  4. é«˜ä¿¡å¿ƒé æ¸¬æ¯”ä¾‹: {high_confidence_count}/{len(y_pred)} ({high_confidence_count/len(y_pred)*100:.1f}%)")

# é¡¯ç¤ºé æ¸¬ vs çœŸå¯¦çš„æ³¢é•·åˆ†ä½ˆçµ±è¨ˆ
print(f"\nğŸ“Š æ³¢é•·ä½¿ç”¨çµ±è¨ˆ:")
for orig_wavelength in sorted(unique_labels):
    mapped_class = label_mapping[orig_wavelength]
    pred_count = np.sum(y_pred_classes == mapped_class)
    true_count = np.sum(y_test_classes == mapped_class)
    print(f"  æ³¢é•· {orig_wavelength}: é æ¸¬ {pred_count} æ¬¡, å¯¦éš› {true_count} æ¬¡")