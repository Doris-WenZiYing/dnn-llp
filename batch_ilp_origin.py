import os
import numpy as np
import pandas as pd
import networkx as nx
from pulp import *

# ====== åƒæ•¸è¨­å®š ======
N = 5
K_PATHS = 3
MAX_WAVELENGTH = 10
INPUT_DIR = "tms_5nodes"
OUTPUT_CSV = "train_dataset_origin.csv"

# ====== å»ºç«‹æ‹“æ¨¸ ======
G = nx.complete_graph(N, create_using=nx.DiGraph())
for u, v in G.edges():
    G[u][v]['length'] = 1  # å¯è‡ªè¨‚è·é›¢æ¬Šé‡

# ====== å»ºç«‹å€™é¸è·¯å¾‘è¡¨ï¼ˆæ¯çµ„ demand æœ€å¤š K æ¢ï¼‰======
from networkx.algorithms.simple_paths import all_simple_paths

def k_shortest_paths(graph, source, target, k):
    all_paths = list(all_simple_paths(graph, source, target, cutoff=6))  # é•·åº¦é™åˆ¶é˜²æ­¢çˆ†ç‚¸
    all_paths = sorted(all_paths, key=lambda p: len(p))  # çŸ­çš„æ’å‰é¢
    return all_paths[:k]

paths = {}
for s in range(N):
    for d in range(N):
        if s != d:
            try:
                paths[(s, d)] = k_shortest_paths(G, s, d, K_PATHS)
            except:
                paths[(s, d)] = []

# ====== é–‹å§‹è™•ç†æ¯ç­† TM ======
X_data = []
Y_data = []

for file in sorted(os.listdir(INPUT_DIR)):
    if not file.endswith(".csv"):
        continue

    tm_path = os.path.join(INPUT_DIR, file)
    tm = pd.read_csv(tm_path, header=None).values
    flat_tm = tm.flatten()

    # ====== å»ºç«‹ ILP ======
    model = LpProblem("RWA_ILP", LpMinimize)
    x = {}

    for (s, d), path_list in paths.items():
        for p_id, path in enumerate(path_list):
            for w in range(MAX_WAVELENGTH):
                var = LpVariable(f"x_{s}_{d}_{p_id}_{w}", 0, 1, LpBinary)
                x[(s, d, p_id, w)] = var

    model += lpSum(x.values()), "Minimize_Total_Resources"

    # æ¯å€‹ demand åªèƒ½é¸ä¸€å€‹ (path, wavelength)
    for (s, d), path_list in paths.items():
        model += lpSum(x[(s, d, p_id, w)] for p_id in range(len(path_list)) for w in range(MAX_WAVELENGTH)) == 1

    # link-wavelength ä¸å¾—è¡çª
    for u, v in G.edges():
        for w in range(MAX_WAVELENGTH):
            conflict_terms = []
            for (s, d), path_list in paths.items():
                for p_id, path in enumerate(path_list):
                    if (u, v) in zip(path, path[1:]):
                        conflict_terms.append(x[(s, d, p_id, w)])
            if conflict_terms:
                model += lpSum(conflict_terms) <= 1

    # ====== æ±‚è§£ ======
    model.solve()

    # ====== è¨˜éŒ„è³‡æ–™ (flattened TM â†’ label) ======
    for (s, d), path_list in paths.items():
        for p_id, path in enumerate(path_list):
            for w in range(MAX_WAVELENGTH):
                if x[(s, d, p_id, w)].varValue == 1:
                    label = p_id * MAX_WAVELENGTH + w
                    X_data.append(flat_tm)
                    Y_data.append(label)

    print(f"âœ… {file} è™•ç†å®Œæˆï¼Œå…±ç”¢ç”Ÿ {len(paths)*1} ç­†æ¨£æœ¬")

# ====== å­˜æˆè¨“ç·´æª” ======
df = pd.DataFrame(X_data)
df['label'] = Y_data
df.to_csv(OUTPUT_CSV, index=False)
print(f"\nğŸ¯ å®Œæˆè¨“ç·´è³‡æ–™å„²å­˜ï¼š{OUTPUT_CSV}ï¼ˆå…± {len(Y_data)} ç­†ï¼‰")
